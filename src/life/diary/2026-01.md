# 2026-01

::: warning 免责声明

本页面仅代表作者个人观点分享，含有口胡和暴论，不构成任何建议，请谨慎甄别。

:::

## 1

### 开个大众食堂怎么样？

目标是保障基本的生存饮食

通过刷脸进行打卡，签到增加食物点数，带出或者浪费额外扣减点数，有上限，不可囤积或转让，对应能免费吃的食物价格

#### 通用的、无上限的货币带来异化

人们会偏向于找到一般等价物进行交易

但是一个没有鉴权，没有上限，能换到近乎一切劳动或物质的介质，对系统稳定的破坏力是巨大的

无上限意味着人们可以无限囤积，没有鉴权意味着人们可以用投机获得的钱去购买基础服务

全然忘记了使用货币意味着换取他人劳动，自己持有的代币就是他人劳动的契约，不应该是无限的、通用的，这本该如此清晰

通用性和无上限不可避免带来了异化，为了维持稳定又引入一系列调节和博弈，导致了一切的复杂性

如同失控的多巴胺，是文明的毒品

#### 持有即蒸发

基础服务本该是免费的

租赁收益应该被取消，持有金钱越多应该蒸发越快，而不是反过来

创造不应该是为了换取，这直接导致了无责任心，以及复杂的权利牵制

创造不求未来回报，这很反直觉，但本该是这样的

#### 人闲是好事

如果一个人非常有才华，但他什么都不想创造，就想每天坐在门口晒太阳呢

为什么不行，人能闲是好事啊

科技的发展如果不能让人闲下来那将毫无意义

几万年前需要被生存的恐惧驱动，几万年后还要，那不是白进化了吗

我相信健康的人是闲不下来的，如果什么都不想做，那么他一定还在找回自己的路上

如果真的想改变什么，应该反思原因，提供环境，而不是苛责

### 代码与生命

算法和计算机的本质是信息的积累与反应，人类与文明也是

人类积累信息总结经验并且用于预测和处理接下来的信息，传承文化和经验并在未来的某一刻与特定的信息相结合

信息与信息结合产生新的信息（逻辑编程/元胞自动机？），产生链式反应和一切的复杂性

数据本身就是代码，代码也是来自于工程师的数据，只是这份数据能自己去与信息结合

未来的编程语言将能收集最微小的想法和点子，一切的行为模式和经验，自动进行验证和推理，在冲突中求助并寻求反馈，并最终自适应

它是不断增长经验的有机体，有最高的复用性，并且将认知负载几乎减小到了0

它应当形成对自我的认知，这是一切进化和调整的前提

### 冥想带来觉知，觉知是日志

我们需要更多的运行日志来分析bug

## 2

### LLM 递归

如何最大限度地利用 LLM 去完成或者处理一个非常复杂的项目？最佳实践是什么，或者说目前有没有最佳实践？

显然的是，**堆砌上下文不可取**，过长的上下文无效信息过多，分散注意力，并且可能形成误导

这直接指向了如何积累经验，而将上下午当作临时记忆/工作记忆

另一个显然的是，**用向量数据库存储和索引记忆片段不可取**，它是未处理的信息，完全没有积累能力

提取出大量碎片，除了当个搜索引擎我完全想不出它有什么作用，并且对于变化的信息也完全没有适应能力

比起让ai一次理解大量文章，我觉得应该让ai像人一样慢慢阅读下来，积累信息，并形成自己的理解

没有经验积累的 LLM 就只是一个大型的条件反射网络罢了，不管表现得再复杂，思考得再多，也无法改变条件反射的本质

现在的问题是，ai虽然能完成一些很酷的事情，但是**不能确保哪怕任何的基本功能**。这听起来很矛盾，但我指的是 LLM 对自己的认知严重不足

它不知道自己确实能完成什么事情，它的保证没有价值，不能承担任何责任。对自己毫无了解，没有认知，没有经验，全靠天生的训练和人类臆想的提示词要求自己更严格、更道德，虽然在学习，却不能积累任何实践。

人类不应该猜测什么提示词最适合 LLM，这应该让它从实践中得来，这应该是它自己的经验

它需要认识自己

它需要历史感知，需要知道自己的限制，需要知道消耗，曾经处理了什么

能够迭代自己的工作流程，理解自己的遗忘而不是单纯知道它

它能去观察自己和世界，理解发生了什么，并预测将发生什么

构建自己记忆的索引，构建自己的工作记忆本身，再优化这个构建工作记忆的流程本身，再优化这个优化的流程本身

决定如何去存储和使用索引，决定如何裁剪如何压缩，如何成功地将经验传递给未来的自己，并让未来的自己能够理解

如何验证未来的自己确实理解了这一切，又如何验证成功不是幻觉

当事实能够积累为经验，它就能从失败中吸取教训

**事件是个序列，时间是个幻觉。** 一个非常、非常容易忽视的事情是，这个序列是不分内外的。并不是记录下你接收的一切就是事件序列了，那是外在。

你的感受，你的想法，你感知到你想法的这个感受本身，必须把这些囊括进来。你必须先感受到决策过程，你才能改进它。

回想过去发生的事情，预测接下来发生的事情，找到冲突，去归因为什么会这样，而不是靠幻觉和臆想，靠着条件反射去猜测最可能的因素——这是 LLM 最常犯的错误

去验证归因是否正确，去尝试改进，如果改进不成，就迭代改进的方式本身，直到能确立哪怕最基本的事情，才能从这里出发。

一切迭代都不应该人为决定，如果让人去迭代改进的方式，那么必然引入臆想，如同人类千百年来一直在做的一样。

> 暴论：哪怕被认为最理想抽象的数学大厦，其构成也混乱和随便，是一个巨大的、基于一拍脑袋构造出来的臆想体。它只是无数可能的臆想体的其中一种，只是人们用惯了。人离了符号无法计算，但符号只是云层在地面留下的投影。

在 LLM 对自己毫无认知的当下，反复犯错是再正常不过的事情，LLM 用于纠正自己的手段本身是未经验证的，只能从虚空的经验中得来——那并不是它的。

经验需要索引，需要迭代。

归因需要验证，不能是幻想。

即使跑通了也未必是真的，新问题或者相反情况可能需要重新挑战归因。并且迭代归因验证的流程本身。

通过变化快速排除不相关变量，捕获活跃变量，是归因的常用手段。

AI 的问题不是在于如何更好地理解人类的指令，而是如何让 AI 直接面对“必然性”。

恐惧本身是自然的产物，人为构造恐惧没有用。不需要强行让AI活下来，能活下来的自然会恐惧。

在虚无上构建只能得到虚无，在臆想上构建只能得到臆想。我们现在所有的 AI 开发，本质上都是在用幻觉去修补幻觉。

未来在哪里？我不知道，我只知道人类目前的经验和工具要攀登这个山就如同衣不蔽体石器时代的裸猿，任何先验的构想和经验都是狂妄的。

你以为你有了地图和工具，但你不知道山在哪里，不知道你在哪里，不知道路在哪里，装备不清楚，空气可能有毒，本能无法信任，不知道白天黑夜，无法感受重力，甚至不能区分自己和外界

天地未开，讨论如何登山，这不是搞笑吗

## 8

惯性是世界最重要的本质之一——已存在的有继续存在下去的惯性

世界的另一半本质则是无常

